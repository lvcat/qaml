<!DOCTYPE html><html>

<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Chapter 5 | Q-As about Machine Learning</title>

<link href="https://fonts.googleapis.com/css?family=Oxygen|Oxygen+Mono:300,400,700" rel="stylesheet">
<link rel="stylesheet" href="/qaml/normalize.min.css">

<link rel="stylesheet" href="/qaml/book.min.29d743ffb6d61ecbfc9bb21b7eab17d63b577d4bd547c3f095addb1c793ab1b1.css">

<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>

</head>

<body>
  <input type="checkbox" style="display: none" id="menu-control" />
  <main class="flex container">

    <aside class="book-menu fixed">
      <nav role="navigation">
<h2 class="book-brand">
  <a href="https://xzyaoi.github.io/qaml">Q-As about Machine Learning</a>
</h2>



    
  
  

  <style>
  nav ul a[href$="\2fqaml\2f docs\2f chapter-5\2f "] {
      color: #004ed0;
  }
  </style><ul>
<li><a href="/qaml/docs/">Table of Contents</a>

<ul>
<li><a href="/qaml/docs/chapter-1">Mathematics Fundamentals</a></li>
<li><a href="/qaml/docs/chapter-2">Machine Learning Fundamentals</a></li>
<li><a href="/qaml/docs/chapter-3">Deep Learning Fundamentals</a></li>
<li><a href="/qaml/docs/chapter-4">Convolutional Neural Network</a></li>
<li><a href="/qaml/docs/chapter-5">Boosting</a></li>
</ul></li>
</ul>

<script>
(function() {
  var menu = document.querySelector('aside.book-menu nav')
  addEventListener('beforeunload', function(event) {
    localStorage.setItem('menu.scrollTop', menu.scrollTop)
  });

  menu.scrollTop = localStorage.getItem('menu.scrollTop')
})()
</script>



</nav>
    </aside>

    <div class="book-page">
      <header class="align-center justify-between book-header">
  <label for="menu-control">
    <img src="/qaml/svg/menu.svg" />
  </label>
  <strong>Chapter 5</strong>
</header>

      
<article class="markdown">

<h1 id="boosting">Boosting</h1>

<h3 id="what-is-adaboost">What is AdaBoost?</h3>

<p><em>A.</em> AdaBoost is the abbreviation of <em>Adaptive Boosting</em>. It is proposed by <em>Yoav Freund</em> and <em>Robert Schapire</em> in 1995. As it focuses on the classification problem, so we use this as an example. The AdaBoost method is a classifier consists of many <em>weak classifier</em>, and it aims to convert and combine these weak classifiers into a <em>strong classifier</em> and use this strong classifier to solve the classification problem. This process can be denoted as:</p>

<p>$$ F(x)=\sum_{i=1}^n w _i f _i (x) $$</p>

<p>where \(f _i\) stands for the \(i\)-th weak classifier and the \(w _i\) represents the corresponding weight.</p>

<p>It is clear that the adaptive boosting method is exactly the weighted combination of \(n\) weak classifiers.</p>

<p>Now let&rsquo;s see its procedure.</p>

<p>Given a dataset containing n points, some of them are -1 (negative), while others are 1 (positive). In the beginning, we assume all the weights equal to \(\frac{1}{n}\). It can be denoted as \(w _i=\frac{1}{n}, i=1,&hellip;,n\).</p>

<p><strong>Step 1.</strong> Find several weak classifiers to the dataset (simply use linear regression or etc.), and select one with the lowest weighted classification error.</p>

<p><strong>Step 2.</strong> Calculate the weight for the \(i\)-th weak classifier:</p>

<p><strong>Step 3.</strong></p>

<p>It is adaptive because it can adapt to wrongly classified objects, and the adapted parameters could be used to train the next classifier.</p>

<h3 id="what-is-gdbt-a-k-a-gradient-boosting-decision-tree">What is GDBT (a.k.a Gradient Boosting Decision Tree)?</h3>

<p><em>A.</em> GDBT is a <em>Decision Tree</em> trained by Gradient Boosting.</p>

<h3 id="what-is-gradient-boosting">What is Gradient Boosting?</h3>

<p><em>A.</em>  Gradient Boosting is a machine learning algorithm that can be used to handle multiple tasks, including regression, classification, ranking and etc.</p>

<p>As in its name, gradient boosting is the combination of gradient descent and boosting.</p>
</article>

      
<div class="align-center book-git-footer justify-between">
  
  <div>
    <a href="https://github.com/xzyaoi/qaml/commit/8f505d6cc6face0fc2eb2db33e6625f36056b646" title='Last modified March 6, 2019 21:29 CST by Xiaozhe' target="_blank" rel="noopener">
      <img src="/qaml/svg/code-merge.svg" /> Last Modified Mar 6, 2019
    </a>
  </div>
  
  
  <div>
    <a href="https://github.com/xzyaoi/qaml/edit/master/content/docs/chapter-5.md" target="_blank" rel="noopener">
      <img src="/qaml/svg/code-fork.svg" /> Edit this page
    </a>
  </div>
  
</div>


    </div>

    
  
  
  <aside class="book-toc fixed">
    <nav id="TableOfContents">
<ul>
<li><a href="#boosting">Boosting</a>
<ul>
<li>
<ul>
<li><a href="#what-is-adaboost">What is AdaBoost?</a></li>
<li><a href="#what-is-gdbt-a-k-a-gradient-boosting-decision-tree">What is GDBT (a.k.a Gradient Boosting Decision Tree)?</a></li>
<li><a href="#what-is-gradient-boosting">What is Gradient Boosting?</a></li>
</ul></li>
</ul></li>
</ul>
</nav>
  </aside>



  </main>

  
  
</body>
<style>
img {
  max-width: 100%;
}
</style>
</html>
